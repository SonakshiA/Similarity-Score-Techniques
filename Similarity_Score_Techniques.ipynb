{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObPff5d2Abav0fTi7L9v/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonakshiA/Similarity-Score-Techniques/blob/master/Similarity_Score_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpE6ez_cwLpk",
        "outputId": "99db1bbb-6359-4294-e47b-17b5ea8a2b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6c723602fc10e3c4767872b6f9b7c0575b7699bac038a1d8f8f2603bb9b75462\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYu7J7X6IaVu",
        "outputId": "9fb8d116-60b9-4639-fc59-ef306098bb33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pot\n",
            "  Downloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from pot) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from pot) (1.13.1)\n",
            "Downloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (835 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/835.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m835.4/835.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pot\n",
            "Successfully installed pot-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlUX5zQzrdV",
        "outputId": "0260d4bc-7bff-4fd7-812a-a5a95a2092a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296185 sha256=bc27e386ac2358cdcc0489b9b3a21f2b2b959add05b67024ffacce2de1e65021\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Cosine Similarity**"
      ],
      "metadata": {
        "id": "d7mIzQwnpgvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ON2t18pcOY",
        "outputId": "85007764-1eb2-42f6-ce51-3e8310ba4c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.959403223600247\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Similar sentences\n",
        "text1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text2 = \"The quick brown fox jumps over a lazy dog.\"\n",
        "\n",
        "# Convert texts to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "\n",
        "print(f\"Cosine Similarity: {cosine_sim[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. BLEU Score**"
      ],
      "metadata": {
        "id": "5aHEh42tsml4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Reference and candidate sentences\n",
        "reference = \"The quick brown fox jumps over the lazy dog.\"\n",
        "candidate = \"The fast brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize sentences into words\n",
        "reference_tokens = [reference.split()]  # Reference is wrapped in a list of lists\n",
        "candidate_tokens = candidate.split()\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqjR1c38qKUi",
        "outputId": "a92963cb-fd8c-41df-f124-e3f9df18af92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.7506238537503395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. ROGUE Score**"
      ],
      "metadata": {
        "id": "ZZj4HvPSvuLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Reference and candidate summaries\n",
        "reference = \"The quick brown fox jumps over the lazy dog.\"\n",
        "candidate = \"The fast brown fox jumps over the lazy dog.\"\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "scores = scorer.score(reference,candidate)['rouge1']\n",
        "\n",
        "# Display ROUGE-1 score\n",
        "print(f\"ROUGE-1 (Unigram) Score: {scores.precision}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfjR4c9bvxDH",
        "outputId": "79676211-82c6-48b0-dcac-9c10b13114d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 (Unigram) Score: 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Jaccard Similarity**"
      ],
      "metadata": {
        "id": "h63SgAxFywa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(text1, text2):\n",
        "    # Tokenize the sentences into sets of words\n",
        "    set1 = set(text1.lower().split())\n",
        "    set2 = set(text2.lower().split())\n",
        "\n",
        "    # Calculate the intersection and union of the sets\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "\n",
        "    # Calculate Jaccard similarity\n",
        "    jaccard_sim = len(intersection) / len(union)\n",
        "    return jaccard_sim\n",
        "\n",
        "# Sample texts\n",
        "text1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text2 = \"The fast brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Calculate Jaccard similarity\n",
        "similarity = jaccard_similarity(text1, text2)\n",
        "print(f\"Jaccard Similarity: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UFkbJlbyzVJ",
        "outputId": "d3f4cfa7-6e3a-4573-b403-5d0dfb1a772d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity: 0.7778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Word Mover's Distance**"
      ],
      "metadata": {
        "id": "jYsmMNybzv1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec embeddings\n",
        "word_vectors = api.load(\"word2vec-google-news-300\")  # This may take a while to download\n",
        "\n",
        "# Define two sample sentences\n",
        "text1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text2 = \"The fast brown fox leaps over the lazy dog.\"\n",
        "\n",
        "# Tokenize and preprocess the sentences\n",
        "text1_tokens = text1.lower().split()\n",
        "text2_tokens = text2.lower().split()\n",
        "\n",
        "# Calculate Word Mover's Distance\n",
        "distance = word_vectors.wmdistance(text1_tokens, text2_tokens)\n",
        "print(f\"Word Mover's Distance: {distance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UYHLi3RzvB9",
        "outputId": "bb713285-b553-40d7-cc66-2bcc351b7c6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Mover's Distance: 0.2272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Euclidean Distance**"
      ],
      "metadata": {
        "id": "brIAE6qVLtAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "def get_sentence_vector(text, model):\n",
        "    words = text.lower().split()  # Tokenize and lowercased\n",
        "    word_vectors = [model[word] for word in words if word in model]  # Get vectors for words present in the model\n",
        "    if word_vectors:  # Avoid empty vectors\n",
        "        sentence_vector = np.mean(word_vectors, axis=0)  # Average word vector for the sentence\n",
        "        return sentence_vector\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)  # Return a zero vector if no words are in the model\n",
        "\n",
        "text1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text2 = \"The fast brown fox leaps over the lazy dog.\"\n",
        "vector1 = get_sentence_vector(text1, model)\n",
        "vector2 = get_sentence_vector(text2, model)\n",
        "distance = euclidean(vector1, vector2)\n",
        "\n",
        "print(f\"Euclidean Distance: {distance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6mTbqziLpiV",
        "outputId": "729bc4b3-c10d-4ed6-cec2-1964f16ef130"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Distance: 0.4865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# Load a pre-trained Word2Vec model (e.g., \"word2vec-google-news-300\")\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Function to calculate Euclidean distance between two words\n",
        "def calculate_word_distance(word1, word2, model):\n",
        "    if word1 in model and word2 in model:\n",
        "        # Get the vectors for both words\n",
        "        vector1 = model[word1]\n",
        "        vector2 = model[word2]\n",
        "\n",
        "        # Calculate Euclidean distance\n",
        "        distance = euclidean(vector1, vector2)\n",
        "        return distance\n",
        "    else:\n",
        "        print(f\"One or both words not found in the model: {word1}, {word2}\")\n",
        "        return None\n",
        "\n",
        "# Define two words\n",
        "word1 = \"man\"\n",
        "word2 = \"king\"\n",
        "\n",
        "# Calculate Euclidean distance\n",
        "distance = calculate_word_distance(word1, word2, model)\n",
        "\n",
        "# Display the result\n",
        "if distance is not None:\n",
        "    print(f\"Euclidean Distance between '{word1}' and '{word2}': {distance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w7Sm2PuL-UM",
        "outputId": "3f4909c7-8bfa-4900-bb55-0a7ff32d42f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Distance between 'man' and 'king': 3.2688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity is sensitive to the exact word choice. Even though it measures the angle between two vectors, if two sentences or documents use different terms that have similar meanings, cosine similarity might not capture their similarity well.\n",
        "\n",
        "The code snippet below highlights this drawback of cosine similarity:"
      ],
      "metadata": {
        "id": "a4W9I7PiRy_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Similar sentences\n",
        "text1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text2 = \"A fast brown fox leaps over the sleepy dog.\"\n",
        "\n",
        "# Convert texts to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "\n",
        "print(f\"Cosine Similarity: {cosine_sim[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5QpXzwjSDJa",
        "outputId": "46f028d5-a698-4320-f8c6-fc5ce51a8780"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.4864156960410001\n"
          ]
        }
      ]
    }
  ]
}